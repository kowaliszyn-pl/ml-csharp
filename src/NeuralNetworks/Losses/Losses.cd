<?xml version="1.0" encoding="utf-8"?>
<ClassDiagram MajorVersion="1" MinorVersion="1">
  <Class Name="NeuralNetworks.Losses.Loss&lt;TPrediction&gt;" Collapsed="true">
    <Position X="1.75" Y="1.75" Width="1.5" />
    <TypeIdentifier>
      <HashCode>AAAAAASACAAAAAAAAAAAACAEQAAAAABAEACAAAAAABI=</HashCode>
      <FileName>Losses\Loss.cs</FileName>
    </TypeIdentifier>
  </Class>
  <Class Name="NeuralNetworks.Losses.Loss2D" Collapsed="true">
    <Position X="1.75" Y="3" Width="1.5" />
    <TypeIdentifier>
      <HashCode>AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAAAAAA=</HashCode>
      <FileName>Losses\Loss2D.cs</FileName>
    </TypeIdentifier>
  </Class>
  <Class Name="NeuralNetworks.Losses.MeanSquaredError" Collapsed="true">
    <Position X="1" Y="4.75" Width="1.75" />
    <TypeIdentifier>
      <HashCode>AAAAAAAACAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAA=</HashCode>
      <FileName>Losses\MeanSquaredError.cs</FileName>
    </TypeIdentifier>
  </Class>
  <Class Name="NeuralNetworks.Losses.SoftmaxCrossEntropyLoss" Collapsed="true">
    <Position X="3" Y="4.75" Width="2.5" />
    <TypeIdentifier>
      <HashCode>AAAAAAAACAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAA=</HashCode>
      <FileName>Losses\SoftmaxCrossEntropyLoss.cs</FileName>
    </TypeIdentifier>
  </Class>
  <Class Name="NeuralNetworks.Losses.SoftmaxLogSumExpCrossEntropyLoss" Collapsed="true">
    <Position X="5.75" Y="4.75" Width="3.25" />
    <TypeIdentifier>
      <HashCode>AAAAAAAACAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAA=</HashCode>
      <FileName>Losses\SoftmaxLogSumExpCrossEntropyLoss.cs</FileName>
    </TypeIdentifier>
  </Class>
  <Font Name="Segoe UI" Size="9" />
</ClassDiagram>